{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30479985",
   "metadata": {
    "id": "30479985"
   },
   "source": [
    "## Downloading stock market data from the CVM website.\n",
    "## The data will consist of quarterly reports spanning from 2012 to 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f8d4e",
   "metadata": {},
   "source": [
    "### Setting the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b03bf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.max_columns', 10)\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.set_option('display.width', 200)\n",
    "#pd.reset_option('display.width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587cc01",
   "metadata": {},
   "source": [
    "### Installing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a22943e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4540,
     "status": "ok",
     "timestamp": 1693529355133,
     "user": {
      "displayName": "Enok Antônio de Jesus",
      "userId": "15348291901420349452"
     },
     "user_tz": 180
    },
    "id": "7a22943e",
    "outputId": "0cc9306a-7982-4423-c4c5-75b9224324db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /usr/lib/python3.11/site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/lib/python3.11/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.11/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chardet in /usr/lib/python3.11/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: files in /home/enok/.local/lib/python3.11/site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chardet in /usr/lib/python3.11/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4\n",
    "%pip install chardet\n",
    "%pip install files\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55058e",
   "metadata": {},
   "source": [
    "### Downloading balance sheets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6563bd89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135343,
     "status": "ok",
     "timestamp": 1693529493588,
     "user": {
      "displayName": "Enok Antônio de Jesus",
      "userId": "15348291901420349452"
     },
     "user_tz": 180
    },
    "id": "6563bd89",
    "outputId": "b2c3d71e-27dc-4d52-ace6-755b7f4f6077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: itr_cia_aberta_2012.zip\n",
      "File already exists: itr_cia_aberta_2013.zip\n",
      "File already exists: itr_cia_aberta_2014.zip\n",
      "File already exists: itr_cia_aberta_2015.zip\n",
      "File already exists: itr_cia_aberta_2016.zip\n",
      "File already exists: itr_cia_aberta_2017.zip\n",
      "File already exists: itr_cia_aberta_2018.zip\n",
      "File already exists: itr_cia_aberta_2019.zip\n",
      "File already exists: itr_cia_aberta_2020.zip\n",
      "File already exists: itr_cia_aberta_2021.zip\n",
      "File already exists: itr_cia_aberta_2022.zip\n",
      "Download, extraction, file removal, and encoding conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import zipfile\n",
    "import chardet\n",
    "\n",
    "# Function to check if a file's encoding is UTF-8\n",
    "def is_utf8(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            result = chardet.detect(raw_data)\n",
    "            return result['encoding'] == 'utf-8'\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# URL of the website containing the ZIP files\n",
    "base_url = \"https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/\"\n",
    "\n",
    "# Create a directory to save the downloaded files\n",
    "download_dir = \"downloaded_files\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Define the years you want to download (2012 to 2022)\n",
    "years_to_download = set(str(year) for year in range(2012, 2023))\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(base_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all links on the page\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# Iterate through the links and download ZIP files for the specified years\n",
    "for link in links:\n",
    "    file_url = urljoin(base_url, link[\"href\"])\n",
    "    \n",
    "    # Example: Assuming ZIP files are named like \"itr_cia_aberta_YEAR.zip\"\n",
    "    if file_url.endswith(\".zip\"):\n",
    "        zip_file_name = os.path.basename(file_url)\n",
    "        \n",
    "        # Extract the year from the ZIP file name\n",
    "        year_part = zip_file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        # Check if the ZIP file is from a year within the specified range\n",
    "        if year_part in years_to_download:\n",
    "            # Check if the ZIP file already exists\n",
    "            if not os.path.exists(os.path.join(download_dir, zip_file_name)):\n",
    "                print(f\"Downloading: {zip_file_name}\")\n",
    "                with open(os.path.join(download_dir, zip_file_name), \"wb\") as file:\n",
    "                    file_response = requests.get(file_url)\n",
    "                    file.write(file_response.content)\n",
    "            else:\n",
    "                print(f\"File already exists: {zip_file_name}\")\n",
    "\n",
    "# Process the downloaded ZIP files (extract, remove \"ind\" files, and convert)\n",
    "for zip_file_name in os.listdir(download_dir):\n",
    "    if zip_file_name.endswith(\".zip\"):\n",
    "        zip_file_path = os.path.join(download_dir, zip_file_name)\n",
    "        zip_subdir = os.path.splitext(zip_file_name)[0]  # Use ZIP file name without extension as subdirectory name\n",
    "        zip_subdir_path = os.path.join(download_dir, zip_subdir)\n",
    "\n",
    "        # Check if the ZIP file has already been extracted\n",
    "        if not os.path.exists(zip_subdir_path):\n",
    "            print(f\"Unzipping: {zip_file_name} -> {zip_subdir_path}\")\n",
    "            with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(zip_subdir_path)\n",
    "\n",
    "            # Remove files with \"ind\" in their names\n",
    "            for root, _, files in os.walk(zip_subdir_path):\n",
    "                for file_name in files:\n",
    "                    if \"ind\" in file_name:\n",
    "                        file_path = os.path.join(root, file_name)\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Removed: {file_path}\")\n",
    "\n",
    "            # Remove files with \"itr_cia_aberta_20\" in their names\n",
    "            for root, _, files in os.walk(zip_subdir_path):\n",
    "                for file_name in files:\n",
    "                    if \"itr_cia_aberta_20\" in file_name:\n",
    "                        file_path = os.path.join(root, file_name)\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Removed: {file_path}\")\n",
    "\n",
    "            # Remove files with \"itr_cia_aberta_DFC_MD_con_20\" in their names\n",
    "            for root, _, files in os.walk(zip_subdir_path):\n",
    "                for file_name in files:\n",
    "                    if \"itr_cia_aberta_DFC_MD_con_20\" in file_name:\n",
    "                        file_path = os.path.join(root, file_name)\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Removed: {file_path}\")\n",
    "\n",
    "            # Convert CSV files from ISO-8859-1 to UTF-8 only if they are not already UTF-8\n",
    "            for csv_file_name in os.listdir(zip_subdir_path):\n",
    "                if csv_file_name.endswith(\".csv\"):\n",
    "                    csv_file_path = os.path.join(zip_subdir_path, csv_file_name)\n",
    "                    if not is_utf8(csv_file_path):\n",
    "                        print(f\"Converting encoding: {csv_file_path}\")\n",
    "                        with open(csv_file_path, 'r', encoding='ISO-8859-1') as source_file:\n",
    "                            content = source_file.read()\n",
    "                        with open(csv_file_path, 'w', encoding='utf-8') as target_file:\n",
    "                            target_file.write(content)\n",
    "                    else:\n",
    "                        print(f\"File already in UTF-8: {csv_file_path}\")\n",
    "\n",
    "print(\"Download, extraction, file removal, and encoding conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bda8e0",
   "metadata": {},
   "source": [
    "### Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ba9bc4e",
   "metadata": {
    "id": "6ba9bc4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_BPA_con_2012.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 132416\n",
      "Dataframe size - after concat: 132416\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_BPP_con_2012.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 224976\n",
      "Dataframe size - after concat: 224976\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_DFC_MI_con_2012.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 80864\n",
      "Dataframe size - after concat: 80864\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_DMPL_con_2012.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 458552\n",
      "Dataframe size - after concat: 458552\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_DRA_con_2012.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 20887\n",
      "Dataframe size - after concat: 20887\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_DRE_con_2012.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 119445\n",
      "Dataframe size - after concat: 119445\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2012/itr_cia_aberta_DVA_con_2012.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 85694\n",
      "Dataframe size - after concat: 85694\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_BPA_con_2013.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 130188\n",
      "Dataframe size - after concat: 262604\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_BPP_con_2013.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 219866\n",
      "Dataframe size - after concat: 444842\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_DFC_MI_con_2013.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 81144\n",
      "Dataframe size - after concat: 162008\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_DMPL_con_2013.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 453808\n",
      "Dataframe size - after concat: 912360\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_DRA_con_2013.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21142\n",
      "Dataframe size - after concat: 42029\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_DRE_con_2013.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 118622\n",
      "Dataframe size - after concat: 238067\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2013/itr_cia_aberta_DVA_con_2013.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 83962\n",
      "Dataframe size - after concat: 169656\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_BPA_con_2014.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 130971\n",
      "Dataframe size - after concat: 393575\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_BPP_con_2014.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 221196\n",
      "Dataframe size - after concat: 666038\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_DFC_MI_con_2014.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 82769\n",
      "Dataframe size - after concat: 244777\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_DMPL_con_2014.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 458448\n",
      "Dataframe size - after concat: 1370808\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_DRA_con_2014.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21575\n",
      "Dataframe size - after concat: 63604\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_DRE_con_2014.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 119904\n",
      "Dataframe size - after concat: 357971\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2014/itr_cia_aberta_DVA_con_2014.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 84426\n",
      "Dataframe size - after concat: 254082\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_BPA_con_2015.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 128798\n",
      "Dataframe size - after concat: 522373\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_BPP_con_2015.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 216672\n",
      "Dataframe size - after concat: 882710\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_DFC_MI_con_2015.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 83068\n",
      "Dataframe size - after concat: 327845\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_DMPL_con_2015.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 448944\n",
      "Dataframe size - after concat: 1819752\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_DRA_con_2015.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21305\n",
      "Dataframe size - after concat: 84909\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_DRE_con_2015.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 118866\n",
      "Dataframe size - after concat: 476837\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2015/itr_cia_aberta_DVA_con_2015.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 82518\n",
      "Dataframe size - after concat: 336600\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_BPA_con_2016.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 126491\n",
      "Dataframe size - after concat: 648864\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_BPP_con_2016.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 213179\n",
      "Dataframe size - after concat: 1095889\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_DFC_MI_con_2016.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 82632\n",
      "Dataframe size - after concat: 410477\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_DMPL_con_2016.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 440592\n",
      "Dataframe size - after concat: 2260344\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_DRA_con_2016.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21098\n",
      "Dataframe size - after concat: 106007\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_DRE_con_2016.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 114788\n",
      "Dataframe size - after concat: 591625\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2016/itr_cia_aberta_DVA_con_2016.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 80974\n",
      "Dataframe size - after concat: 417574\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_BPA_con_2017.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 128978\n",
      "Dataframe size - after concat: 777842\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_BPP_con_2017.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 217592\n",
      "Dataframe size - after concat: 1313481\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_DFC_MI_con_2017.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 85008\n",
      "Dataframe size - after concat: 495485\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_DMPL_con_2017.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 448064\n",
      "Dataframe size - after concat: 2708408\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_DRA_con_2017.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21590\n",
      "Dataframe size - after concat: 127597\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_DRE_con_2017.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 116638\n",
      "Dataframe size - after concat: 708263\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2017/itr_cia_aberta_DVA_con_2017.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 82626\n",
      "Dataframe size - after concat: 500200\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_BPA_con_2018.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 125196\n",
      "Dataframe size - after concat: 903038\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_BPP_con_2018.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 214792\n",
      "Dataframe size - after concat: 1528273\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_DFC_MI_con_2018.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 85546\n",
      "Dataframe size - after concat: 581031\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_DMPL_con_2018.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 383720\n",
      "Dataframe size - after concat: 3092128\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_DRA_con_2018.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21844\n",
      "Dataframe size - after concat: 149441\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_DRE_con_2018.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 115180\n",
      "Dataframe size - after concat: 823443\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2018/itr_cia_aberta_DVA_con_2018.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 81696\n",
      "Dataframe size - after concat: 581896\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_BPA_con_2019.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 126068\n",
      "Dataframe size - after concat: 1029106\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_BPP_con_2019.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 217079\n",
      "Dataframe size - after concat: 1745352\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_DFC_MI_con_2019.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 86363\n",
      "Dataframe size - after concat: 667394\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_DMPL_con_2019.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 451264\n",
      "Dataframe size - after concat: 3543392\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_DRA_con_2019.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 21647\n",
      "Dataframe size - after concat: 171088\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_DRE_con_2019.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 114292\n",
      "Dataframe size - after concat: 937735\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2019/itr_cia_aberta_DVA_con_2019.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 82248\n",
      "Dataframe size - after concat: 664144\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_BPA_con_2020.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 145676\n",
      "Dataframe size - after concat: 1174782\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_BPP_con_2020.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 251254\n",
      "Dataframe size - after concat: 1996606\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_DFC_MI_con_2020.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 102028\n",
      "Dataframe size - after concat: 769422\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_DMPL_con_2020.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 516017\n",
      "Dataframe size - after concat: 4059409\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_DRA_con_2020.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 24620\n",
      "Dataframe size - after concat: 195708\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_DRE_con_2020.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 130668\n",
      "Dataframe size - after concat: 1068403\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2020/itr_cia_aberta_DVA_con_2020.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 94746\n",
      "Dataframe size - after concat: 758890\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_BPA_con_2021.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 173012\n",
      "Dataframe size - after concat: 1347794\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_BPP_con_2021.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 298002\n",
      "Dataframe size - after concat: 2294608\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_DFC_MI_con_2021.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 120850\n",
      "Dataframe size - after concat: 890272\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_DMPL_con_2021.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 605398\n",
      "Dataframe size - after concat: 4664807\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_DRA_con_2021.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 28884\n",
      "Dataframe size - after concat: 224592\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_DRE_con_2021.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 152686\n",
      "Dataframe size - after concat: 1221089\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2021/itr_cia_aberta_DVA_con_2021.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 111870\n",
      "Dataframe size - after concat: 870760\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_BPA_con_2022.csv\n",
      "CSV type: BPA\n",
      "Dataframe size: 182138\n",
      "Dataframe size - after concat: 1529932\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_BPP_con_2022.csv\n",
      "CSV type: BPP\n",
      "Dataframe size: 311946\n",
      "Dataframe size - after concat: 2606554\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_DFC_MI_con_2022.csv\n",
      "CSV type: DFC\n",
      "Dataframe size: 130734\n",
      "Dataframe size - after concat: 1021006\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_DMPL_con_2022.csv\n",
      "CSV type: DMPL\n",
      "Dataframe size: 634848\n",
      "Dataframe size - after concat: 5299655\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_DRA_con_2022.csv\n",
      "CSV type: DRA\n",
      "Dataframe size: 31310\n",
      "Dataframe size - after concat: 255902\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_DRE_con_2022.csv\n",
      "CSV type: DRE\n",
      "Dataframe size: 160318\n",
      "Dataframe size - after concat: 1381407\n",
      "\n",
      "-------------------------------------------------------\n",
      "Reading csv file: downloaded_files/itr_cia_aberta_2022/itr_cia_aberta_DVA_con_2022.csv\n",
      "CSV type: DVA\n",
      "Dataframe size: 118502\n",
      "Dataframe size - after concat: 989262\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "bpa_df = None\n",
    "bpp_df = None\n",
    "dfc_mi_df = None\n",
    "dmpl_df = None\n",
    "dra_df = None\n",
    "dre_df = None\n",
    "dva_df = None\n",
    "\n",
    "d_parser = lambda x: pd.datetime.strptime(format='%Y-%m-%d')\n",
    "\n",
    "# Load files into Data Frames\n",
    "for dir_name in os.listdir(download_dir):\n",
    "    if not dir_name.endswith(\".zip\"):\n",
    "        dir_path = os.path.join(download_dir, dir_name)\n",
    "\n",
    "        for csv_file_name in os.listdir(dir_path):\n",
    "            csv_file_path = os.path.join(dir_path, csv_file_name)\n",
    "            print(\"\\n-------------------------------------------------------\")\n",
    "            print(f\"Reading csv file: {csv_file_path}\")\n",
    "\n",
    "            csv_file_type = os.path.splitext(csv_file_name)[0][15:19].replace(\"_\", \"\")\n",
    "            print(f\"CSV type: {csv_file_type}\")\n",
    "\n",
    "            local_df = pd.read_csv(csv_file_path, sep=';')\n",
    "\n",
    "            local_df['DT_REFER'] = pd.to_datetime(local_df['DT_REFER'], format='%Y-%m-%d')\n",
    "            local_df['DT_FIM_EXERC'] = pd.to_datetime(local_df['DT_FIM_EXERC'], format='%Y-%m-%d')\n",
    "\n",
    "            if ((csv_file_type == 'BPA') or (csv_file_type == 'BPP')):\n",
    "                # Subtract 3 months from the 'DT_FIM_EXERC' using vectorized operations\n",
    "                local_df['DT_INI_EXERC'] = local_df['DT_FIM_EXERC'] - pd.DateOffset(months=3)\n",
    "\n",
    "                # Set the day to the 1st day of the month using pd.offsets.MonthBegin(1)\n",
    "                local_df['DT_INI_EXERC'] = local_df['DT_INI_EXERC'] + pd.offsets.MonthBegin(1)\n",
    "\n",
    "                # Reorder the columns to move 'DT_INI_EXERC' to the 8th position\n",
    "                cols = list(local_df.columns)\n",
    "                cols.remove('DT_INI_EXERC')\n",
    "                cols.insert(8, 'DT_INI_EXERC')\n",
    "                local_df = local_df[cols]\n",
    "            else:\n",
    "                local_df['DT_INI_EXERC'] = pd.to_datetime(local_df['DT_INI_EXERC'], format='%Y-%m-%d')\n",
    "\n",
    "            print(f\"Dataframe size: {len(local_df)}\")\n",
    "\n",
    "            match csv_file_type:\n",
    "                case 'BPA':\n",
    "                    if bpa_df is None:\n",
    "                        bpa_df = local_df\n",
    "                    else:\n",
    "                        bpa_df = pd.concat([bpa_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(bpa_df)}\")\n",
    "\n",
    "                case 'BPP':\n",
    "                    if bpp_df is None:\n",
    "                        bpp_df = local_df\n",
    "                    else:\n",
    "                        bpp_df = pd.concat([bpp_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(bpp_df)}\")\n",
    "\n",
    "                case 'DFC':\n",
    "                    if dfc_mi_df is None:\n",
    "                        dfc_mi_df = local_df\n",
    "                    else:\n",
    "                        dfc_mi_df = pd.concat([dfc_mi_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(dfc_mi_df)}\")\n",
    "\n",
    "                case 'DMPL':\n",
    "                    if dmpl_df is None:\n",
    "                        dmpl_df = local_df\n",
    "                    else:\n",
    "                        dmpl_df = pd.concat([dmpl_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(dmpl_df)}\")\n",
    "\n",
    "                case 'DRA':\n",
    "                    if dra_df is None:\n",
    "                        dra_df = local_df\n",
    "                    else:\n",
    "                        dra_df = pd.concat([dra_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(dra_df)}\")\n",
    "\n",
    "                case 'DRE':\n",
    "                    if dre_df is None:\n",
    "                        dre_df = local_df\n",
    "                    else:\n",
    "                        dre_df = pd.concat([dre_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(dre_df)}\")\n",
    "\n",
    "                case 'DVA':\n",
    "                    if dva_df is None:\n",
    "                        dva_df = local_df\n",
    "                    else:\n",
    "                        dva_df = pd.concat([dva_df, local_df])\n",
    "                    print(f\"Dataframe size - after concat: {len(dva_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c5d71",
   "metadata": {},
   "source": [
    "### Data analising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adcb44d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bpa_df: 1,529,932 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "ORDEM_EXERC              object\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 0\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 72\n",
      "DT_FIM_EXERC: 78\n",
      "CD_CONTA: 406\n",
      "DS_CONTA: 5305\n",
      "VL_CONTA: 240482\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Balanço Patrimonial Ativo']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 72\n",
      "DT_FIM_EXERC: 78\n",
      "CD_CONTA: 406\n",
      "DS_CONTA: 5305\n",
      "VL_CONTA: 240482\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "bpp_df: 2,606,554 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "ORDEM_EXERC              object\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 0\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 72\n",
      "DT_FIM_EXERC: 78\n",
      "CD_CONTA: 462\n",
      "DS_CONTA: 7629\n",
      "VL_CONTA: 292142\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Balanço Patrimonial Passivo']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 72\n",
      "DT_FIM_EXERC: 78\n",
      "CD_CONTA: 462\n",
      "DS_CONTA: 7629\n",
      "VL_CONTA: 292142\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "dfc_mi_df: 1,021,006 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "ORDEM_EXERC              object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 4\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 620\n",
      "DT_REFER: 62\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 660\n",
      "CD_CVM: 622\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 48\n",
      "DT_FIM_EXERC: 69\n",
      "CD_CONTA: 113\n",
      "DS_CONTA: 35761\n",
      "VL_CONTA: 224209\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 620\n",
      "DT_REFER: 62\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 660\n",
      "CD_CVM: 622\n",
      "GRUPO_DFP: ['DF Consolidado - Demonstração do Fluxo de Caixa (Método Indireto)']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 48\n",
      "DT_FIM_EXERC: 69\n",
      "CD_CONTA: 113\n",
      "DS_CONTA: 35761\n",
      "VL_CONTA: 224209\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "dmpl_df: 5,299,655 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "ORDEM_EXERC              object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "COLUNA_DF                object\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 24\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 50\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 118\n",
      "DS_CONTA: 9323\n",
      "VL_CONTA: 152457\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Demonstração das Mutações do Patrimônio Líquido']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 50\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 118\n",
      "DS_CONTA: 9323\n",
      "VL_CONTA: 152457\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "dra_df: 255,902 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "ORDEM_EXERC              object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 0\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 102\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 49\n",
      "DS_CONTA: 2581\n",
      "VL_CONTA: 67778\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Demonstração de Resultado Abrangente']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 102\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 49\n",
      "DS_CONTA: 2581\n",
      "VL_CONTA: 67778\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "dre_df: 1,381,407 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "ORDEM_EXERC              object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 0\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 102\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 262\n",
      "DS_CONTA: 4277\n",
      "VL_CONTA: 288527\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Demonstração do Resultado']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 102\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 262\n",
      "DS_CONTA: 4277\n",
      "VL_CONTA: 288527\n",
      "ST_CONTA_FIXA: ['S' 'N']\n",
      "\n",
      "\n",
      "dva_df: 989,262 records\n",
      "-------------------------------------------------------------------\n",
      "\t\t\t TYPES\n",
      "CNPJ_CIA                 object\n",
      "DT_REFER         datetime64[ns]\n",
      "VERSAO                    int64\n",
      "DENOM_CIA                object\n",
      "CD_CVM                    int64\n",
      "GRUPO_DFP                object\n",
      "MOEDA                    object\n",
      "ESCALA_MOEDA             object\n",
      "ORDEM_EXERC              object\n",
      "DT_INI_EXERC     datetime64[ns]\n",
      "DT_FIM_EXERC     datetime64[ns]\n",
      "CD_CONTA                 object\n",
      "DS_CONTA                 object\n",
      "VL_CONTA                float64\n",
      "ST_CONTA_FIXA            object\n",
      "dtype: object\n",
      "\t\t\t NULL VALUES\n",
      "CNPJ_CIA: 0\n",
      "DT_REFER: 0\n",
      "VERSAO: 0\n",
      "DENOM_CIA: 0\n",
      "CD_CVM: 0\n",
      "GRUPO_DFP: 0\n",
      "MOEDA: 0\n",
      "ESCALA_MOEDA: 0\n",
      "ORDEM_EXERC: 0\n",
      "DT_INI_EXERC: 0\n",
      "DT_FIM_EXERC: 0\n",
      "CD_CONTA: 0\n",
      "DS_CONTA: 0\n",
      "VL_CONTA: 0\n",
      "ST_CONTA_FIXA: 0\n",
      "\t\t\t COUNT UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: 6\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: 1\n",
      "MOEDA: 1\n",
      "ESCALA_MOEDA: 2\n",
      "ORDEM_EXERC: 2\n",
      "DT_INI_EXERC: 50\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 212\n",
      "DS_CONTA: 2669\n",
      "VL_CONTA: 226742\n",
      "ST_CONTA_FIXA: 2\n",
      "\t\t\t UNIQUE VALUES\n",
      "CNPJ_CIA: 634\n",
      "DT_REFER: 63\n",
      "VERSAO: [2 1 3 4 5 6]\n",
      "DENOM_CIA: 676\n",
      "CD_CVM: 636\n",
      "GRUPO_DFP: ['DF Consolidado - Demonstração de Valor Adicionado']\n",
      "MOEDA: ['REAL']\n",
      "ESCALA_MOEDA: ['MIL' 'UNIDADE']\n",
      "ORDEM_EXERC: ['PENÚLTIMO' 'ÚLTIMO']\n",
      "DT_INI_EXERC: 50\n",
      "DT_FIM_EXERC: 71\n",
      "CD_CONTA: 212\n",
      "DS_CONTA: 2669\n",
      "VL_CONTA: 226742\n",
      "ST_CONTA_FIXA: ['S' 'N']\n"
     ]
    }
   ],
   "source": [
    "def print_df(df_name, df):\n",
    "    print(f'\\n\\n{df_name}: {len(df):,} records')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('\\t\\t\\t TYPES')\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print('\\t\\t\\t NULL VALUES')\n",
    "    print('CNPJ_CIA: ' + str(df['CNPJ_CIA'].isnull().sum().sum()))\n",
    "    print('DT_REFER: ' + str(df['DT_REFER'].isnull().sum().sum()))\n",
    "    print('VERSAO: ' + str(df['VERSAO'].isnull().sum().sum()))\n",
    "    print('DENOM_CIA: ' + str(df['DENOM_CIA'].isnull().sum().sum()))\n",
    "    print('CD_CVM: ' + str(df['CD_CVM'].isnull().sum().sum()))\n",
    "    print('GRUPO_DFP: ' + str(df['GRUPO_DFP'].isnull().sum().sum()))\n",
    "    print('MOEDA: ' + str(df['MOEDA'].isnull().sum().sum()))\n",
    "    print('ESCALA_MOEDA: ' + str(df['ESCALA_MOEDA'].isnull().sum().sum()))\n",
    "    print('ORDEM_EXERC: ' + str(df['ORDEM_EXERC'].isnull().sum().sum()))\n",
    "    print('DT_INI_EXERC: ' + str(df['DT_INI_EXERC'].isnull().sum().sum()))\n",
    "    print('DT_FIM_EXERC: ' + str(df['DT_FIM_EXERC'].isnull().sum().sum()))\n",
    "    print('CD_CONTA: ' + str(df['CD_CONTA'].isnull().sum().sum()))\n",
    "    print('DS_CONTA: ' + str(df['DS_CONTA'].isnull().sum().sum()))\n",
    "    print('VL_CONTA: ' + str(df['VL_CONTA'].isnull().sum().sum()))\n",
    "    print('ST_CONTA_FIXA: ' + str(df['ST_CONTA_FIXA'].isnull().sum().sum()))\n",
    "\n",
    "    print('\\t\\t\\t COUNT UNIQUE VALUES')\n",
    "    print('CNPJ_CIA: ' + str(len(df['CNPJ_CIA'].unique())))\n",
    "    print('DT_REFER: ' + str(len(df['DT_REFER'].unique())))\n",
    "    print('VERSAO: ' + str(len(df['VERSAO'].unique())))\n",
    "    print('DENOM_CIA: ' + str(len(df['DENOM_CIA'].unique())))\n",
    "    print('CD_CVM: ' + str(len(df['CD_CVM'].unique())))\n",
    "    print('GRUPO_DFP: ' + str(len(df['GRUPO_DFP'].unique())))\n",
    "    print('MOEDA: ' + str(len(df['MOEDA'].unique())))\n",
    "    print('ESCALA_MOEDA: ' + str(len(df['ESCALA_MOEDA'].unique())))\n",
    "    print('ORDEM_EXERC: ' + str(len(df['ORDEM_EXERC'].unique())))\n",
    "    print('DT_INI_EXERC: ' + str(len(df['DT_INI_EXERC'].unique())))\n",
    "    print('DT_FIM_EXERC: ' + str(len(df['DT_FIM_EXERC'].unique())))\n",
    "    print('CD_CONTA: ' + str(len(df['CD_CONTA'].unique())))\n",
    "    print('DS_CONTA: ' + str(len(df['DS_CONTA'].unique())))\n",
    "    print('VL_CONTA: ' + str(len(df['VL_CONTA'].unique())))\n",
    "    print('ST_CONTA_FIXA: ' + str(len(df['ST_CONTA_FIXA'].unique())))\n",
    "\n",
    "    print('\\t\\t\\t UNIQUE VALUES')\n",
    "    print('CNPJ_CIA: ' + str(len(df['CNPJ_CIA'].unique())))\n",
    "    print('DT_REFER: ' + str(len(df['DT_REFER'].unique())))\n",
    "    print('VERSAO: ' + str(df['VERSAO'].unique()))\n",
    "    print('DENOM_CIA: ' + str(len(df['DENOM_CIA'].unique())))\n",
    "    print('CD_CVM: ' + str(len(df['CD_CVM'].unique())))\n",
    "    print('GRUPO_DFP: ' + str(df['GRUPO_DFP'].unique()))\n",
    "    print('MOEDA: ' + str(df['MOEDA'].unique()))\n",
    "    print('ESCALA_MOEDA: ' + str(df['ESCALA_MOEDA'].unique()))\n",
    "    print('ORDEM_EXERC: ' + str(df['ORDEM_EXERC'].unique()))\n",
    "    print('DT_INI_EXERC: ' + str(len(df['DT_INI_EXERC'].unique())))\n",
    "    print('DT_FIM_EXERC: ' + str(len(df['DT_FIM_EXERC'].unique())))\n",
    "    print('CD_CONTA: ' + str(len(df['CD_CONTA'].unique())))\n",
    "    print('DS_CONTA: ' + str(len(df['DS_CONTA'].unique())))\n",
    "    print('VL_CONTA: ' + str(len(df['VL_CONTA'].unique())))\n",
    "    print('ST_CONTA_FIXA: ' + str(df['ST_CONTA_FIXA'].unique()))\n",
    "\n",
    "\n",
    "print_df('bpa_df', bpa_df)\n",
    "print_df('bpp_df', bpp_df)\n",
    "print_df('dfc_mi_df', dfc_mi_df)\n",
    "print_df('dmpl_df', dmpl_df)\n",
    "print_df('dra_df', dra_df)\n",
    "print_df('dre_df', dre_df)\n",
    "print_df('dva_df', dva_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b514ab",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53223452",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpa_df_backup = bpa_df\n",
    "bpp_df_backup = bpp_df\n",
    "dfc_mi_df_backup = dfc_mi_df\n",
    "dmpl_df_backup = dmpl_df\n",
    "dra_df_backup = dra_df\n",
    "dre_df_backup = dre_df\n",
    "dva_df_backup = dva_df\n",
    "\n",
    "# bpa_df = bpa_df_backup\n",
    "# bpp_df = bpp_df_backup\n",
    "# dfc_mi_df = dfc_mi_df_backup\n",
    "# dmpl_df = dmpl_df_backup\n",
    "# dra_df = dra_df_backup\n",
    "# dre_df = dre_df_backup\n",
    "# dva_df = dva_df_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3959829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "setting vl_conta based on escala_moeda: bpa_df\n",
      "setting vl_conta based on escala_moeda: bpp_df\n",
      "setting vl_conta based on escala_moeda: dfc_mi_df\n",
      "setting vl_conta based on escala_moeda: dmpl_df\n",
      "setting vl_conta based on escala_moeda: dra_df\n",
      "setting vl_conta based on escala_moeda: dre_df\n",
      "setting vl_conta based on escala_moeda: dva_df\n",
      "\n",
      "\n",
      "removing non mandatory columns from: bpa_df\n",
      "removing non mandatory columns from: bpp_df\n",
      "removing non mandatory columns from: dfc_mi_df\n",
      "removing non mandatory columns from: dmpl_df\n",
      "removing non mandatory columns from: dra_df\n",
      "removing non mandatory columns from: dre_df\n",
      "removing non mandatory columns from: dva_df\n",
      "\n",
      "\n",
      "removing non used accounts for: bpa_df\n",
      "removing non used accounts for: bpp_df\n",
      "removing non used accounts for: dfc_mi_df\n",
      "removing non used accounts for: dmpl_df\n",
      "removing non used accounts for: dra_df\n",
      "removing non used accounts for: dre_df\n",
      "removing non used accounts for: dva_df\n",
      "\n",
      "\n",
      "selecting companies for: bpa_df\n",
      "companies: CPFE3(18660), CMIG4(2453), ELET6(2437), ENEV3(21237), TAEE11(20257)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m dva_df \u001b[39m=\u001b[39m remove_non_used_accounts(\u001b[39m'\u001b[39m\u001b[39mdva_df\u001b[39m\u001b[39m'\u001b[39m, dva_df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m bpa_df \u001b[39m=\u001b[39m select_companies(\u001b[39m'\u001b[39;49m\u001b[39mbpa_df\u001b[39;49m\u001b[39m'\u001b[39;49m, bpa_df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m bpp_df \u001b[39m=\u001b[39m select_companies(\u001b[39m'\u001b[39m\u001b[39mbpp_df\u001b[39m\u001b[39m'\u001b[39m, bpp_df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m dfc_mi_df \u001b[39m=\u001b[39m select_companies(\u001b[39m'\u001b[39m\u001b[39mdfc_mi_df\u001b[39m\u001b[39m'\u001b[39m, dfc_mi_df)\n",
      "\u001b[1;32m/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcompanies: CPFE3(18660), CMIG4(2453), ELET6(2437), ENEV3(21237), TAEE11(20257)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m companies \u001b[39m=\u001b[39m [\u001b[39m18660\u001b[39m, \u001b[39m2453\u001b[39m, \u001b[39m2437\u001b[39m, \u001b[39m21237\u001b[39m, \u001b[39m20257\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mCD_CVM\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mCD_CVM\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(companies)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/google-drive/cursos/usp/mba/data-science/tcc/code/flowpredict/flowpredict.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/lib64/python3.11/site-packages/pandas/core/frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3969\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3970\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_frame_value(key, value)\n\u001b[1;32m   3971\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m   3972\u001b[0m     is_list_like(value)\n\u001b[1;32m   3973\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique\n\u001b[1;32m   3974\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_indexer_for([key])) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value)\n\u001b[1;32m   3975\u001b[0m ):\n\u001b[1;32m   3976\u001b[0m     \u001b[39m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m/usr/lib64/python3.11/site-packages/pandas/core/frame.py:4100\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4098\u001b[0m len_cols \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m is_scalar(cols) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(cols)\n\u001b[1;32m   4099\u001b[0m \u001b[39mif\u001b[39;00m len_cols \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m-> 4100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4102\u001b[0m \u001b[39m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[1;32m   4103\u001b[0m \u001b[39m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[1;32m   4104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   4105\u001b[0m     loc, (\u001b[39mslice\u001b[39m, Series, np\u001b[39m.\u001b[39mndarray, Index)\n\u001b[1;32m   4106\u001b[0m ):\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# calculate value according to field ESCALA_MOELA\n",
    "def set_vl_conta(df_name, df):\n",
    "    print(f'setting vl_conta based on escala_moeda: {df_name}')\n",
    "    df['VL_CONTA'] = np.where(df['ESCALA_MOEDA'] == 'MIL', df['VL_CONTA'] * 1000, df['VL_CONTA'])\n",
    "    return df\n",
    "\n",
    "def remove_non_mandatory_columns(df_name, df):\n",
    "    print(f'removing non mandatory columns from: {df_name}')\n",
    "    existing_cols = df.columns.intersection(['CNPJ_CIA', 'VERSAO', 'DENOM_CIA', 'MOEDA', 'ESCALA_MOEDA', 'COLUNA_DF', 'ST_CONTA_FIXA'])\n",
    "    return df.drop(columns=existing_cols, axis=1)\n",
    "\n",
    "def remove_non_used_accounts(df_name, df):\n",
    "    print(f'removing non used accounts for: {df_name}')\n",
    "\n",
    "    account_to_be_kept = ['1','1.01','1.01.01','1.01.03','1.01.04','1.02','1.02.03','1.02.03.01','1.02.03.02', \n",
    "                        '2.01','2.01.02','2.01.03','2.01.04', \n",
    "                        '3.01','3.02','3.03','3.04','3.04.01','3.04.02','3.04.03','3.04.04','3.04.05','3.04.06','3.06','3.06.01','3.06.02','3.08','3.08.01','3.08.02','3.11','3.11.01', \n",
    "                        '5.04.06','5.05.01', \n",
    "                        '6.01','6.01.01','6.02','6.03','6.05','6.05.01','6.05.02', \n",
    "                        '7.04.01']\n",
    "    return df[df['CD_CONTA'].isin(account_to_be_kept)]\n",
    "\n",
    "def select_companies(df_name, df):\n",
    "    print(f'selecting companies for: {df_name}')\n",
    "    print('companies: CPFE3(18660), CMIG4(2453), ELET6(2437), ENEV3(21237), TAEE11(20257)')\n",
    "\n",
    "    companies = [18660, 2453, 2437, 21237, 20257]\n",
    "    df['CD_CVM'] = df[df['CD_CVM'].isin(companies)]\n",
    "    return df\n",
    "\n",
    "print(\"\\n\")\n",
    "bpa_df = set_vl_conta('bpa_df', bpa_df)\n",
    "bpp_df = set_vl_conta('bpp_df', bpp_df)\n",
    "dfc_mi_df = set_vl_conta('dfc_mi_df', dfc_mi_df)\n",
    "dmpl_df = set_vl_conta('dmpl_df', dmpl_df)\n",
    "dra_df = set_vl_conta('dra_df', dra_df)\n",
    "dre_df = set_vl_conta('dre_df', dre_df)\n",
    "dva_df = set_vl_conta('dva_df', dva_df)\n",
    "\n",
    "print(\"\\n\")\n",
    "bpa_df = remove_non_mandatory_columns('bpa_df', bpa_df)\n",
    "bpp_df = remove_non_mandatory_columns('bpp_df', bpp_df)\n",
    "dfc_mi_df = remove_non_mandatory_columns('dfc_mi_df', dfc_mi_df)\n",
    "dmpl_df = remove_non_mandatory_columns('dmpl_df', dmpl_df)\n",
    "dra_df = remove_non_mandatory_columns('dra_df', dra_df)\n",
    "dre_df = remove_non_mandatory_columns('dre_df', dre_df)\n",
    "dva_df = remove_non_mandatory_columns('dva_df', dva_df)\n",
    "\n",
    "print(\"\\n\")\n",
    "bpa_df = remove_non_used_accounts('bpa_df', bpa_df)\n",
    "bpp_df = remove_non_used_accounts('bpp_df', bpp_df)\n",
    "dfc_mi_df = remove_non_used_accounts('dfc_mi_df', dfc_mi_df)\n",
    "dmpl_df = remove_non_used_accounts('dmpl_df', dmpl_df)\n",
    "dra_df = remove_non_used_accounts('dra_df', dra_df)\n",
    "dre_df = remove_non_used_accounts('dre_df', dre_df)\n",
    "dva_df = remove_non_used_accounts('dva_df', dva_df)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# bpa_df = select_companies('bpa_df', bpa_df)\n",
    "# bpp_df = select_companies('bpp_df', bpp_df)\n",
    "# dfc_mi_df = select_companies('dfc_mi_df', dfc_mi_df)\n",
    "# dmpl_df = select_companies('dmpl_df', dmpl_df)\n",
    "# dra_df = select_companies('dra_df', dra_df)\n",
    "# dre_df = select_companies('dre_df', dre_df)\n",
    "# dva_df = select_companies('dva_df', dva_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7c98e",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add67c4",
   "metadata": {},
   "source": [
    "#### Merge dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([bpa_df, bpp_df, dfc_mi_df, dmpl_df, dra_df, dre_df, dva_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336972c",
   "metadata": {},
   "source": [
    "#### Create function and operation to use for ORDEM_EXERC of value 'PENÚLTIMO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to move 'ORDEM_EXERC' to the last position\n",
    "cols = list(df.columns)\n",
    "cols.remove('ORDEM_EXERC')\n",
    "cols.insert(-1, 'ORDEM_EXERC')\n",
    "df = df[cols]\n",
    "\n",
    "# Reorder the columns to move 'CD_CONTA' to the 2nd position\n",
    "cols = list(df.columns)\n",
    "cols.remove('CD_CONTA')\n",
    "cols.insert(2, 'CD_CONTA')\n",
    "df = df[cols]\n",
    "\n",
    "def createPenultimo(columnName, position, df, objectType):\n",
    "    df[columnName + '_PENULTIMO'] = np.where(\n",
    "        df['ORDEM_EXERC'] == 'PENÚLTIMO', \n",
    "        df[columnName], \n",
    "        None)\n",
    "\n",
    "    # remove this same values from column\n",
    "    df[columnName] = np.where(\n",
    "        df['ORDEM_EXERC'] != 'PENÚLTIMO', \n",
    "        df[columnName], \n",
    "        None)\n",
    "    \n",
    "    match objectType:\n",
    "        case 'DATE_TIME':\n",
    "            df[columnName + '_PENULTIMO'] = pd.to_datetime(df[columnName + '_PENULTIMO'], format='%Y-%m-%d')\n",
    "            df[columnName] = pd.to_datetime(df[columnName], format='%Y-%m-%d')\n",
    "        case 'FLOAT':\n",
    "            df[columnName + '_PENULTIMO'] = df[columnName + '_PENULTIMO'].astype(float)\n",
    "            df[columnName] = df[columnName].astype(float)\n",
    "        # case 'STRING':\n",
    "        #     df[columnName + '_PENULTIMO'] = df[columnName + '_PENULTIMO'].astype(str)\n",
    "        #     df[columnName] = df[columnName].astype(str)\n",
    "\n",
    "    # Reorder the columns to move to correct position\n",
    "    cols = list(df.columns)\n",
    "    cols.remove(columnName + '_PENULTIMO')\n",
    "    cols.insert(position, columnName + '_PENULTIMO')\n",
    "    df = df[cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a3271",
   "metadata": {},
   "source": [
    "#### Create column 'DT_INI_EXERC_PENULTIMO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a470a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createPenultimo('DT_INI_EXERC', 4, df, 'DATE_TIME')\n",
    "\n",
    "print(df.dtypes)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c2549",
   "metadata": {},
   "source": [
    "#### Create column 'DT_FIM_EXERC_PENULTIMO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createPenultimo('DT_FIM_EXERC', 6, df, 'DATE_TIME')\n",
    "print(df.dtypes)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b915e",
   "metadata": {},
   "source": [
    "#### Create column 'VL_CONTA_PENULTIMO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86430632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createPenultimo('VL_CONTA', 10, df, 'FLOAT')\n",
    "\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73545271",
   "metadata": {},
   "source": [
    "#### Remove disposable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53164a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.intersection(['GRUPO_DFP', 'DS_CONTA', 'ORDEM_EXERC'])\n",
    "df = df.drop(columns=cols, axis=1)\n",
    "\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ab015",
   "metadata": {},
   "source": [
    "#### Group by 'DT_REFER', 'CD_CVM', and 'CD_CONTA' and aggregate the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ec0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_funcs = {\n",
    "    'DT_INI_EXERC_PENULTIMO': 'first',\n",
    "    'DT_INI_EXERC': 'first',\n",
    "    'DT_FIM_EXERC_PENULTIMO': 'first',\n",
    "    'DT_FIM_EXERC': 'first',\n",
    "    'VL_CONTA_PENULTIMO': 'last',\n",
    "    'VL_CONTA': 'last'\n",
    "}\n",
    "\n",
    "df = df.groupby(['DT_REFER', 'CD_CVM', 'CD_CONTA']).agg(agg_funcs).reset_index()\n",
    "\n",
    "# Reorder the columns as needed\n",
    "df = df[['DT_REFER', 'CD_CVM', 'CD_CONTA', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC', 'VL_CONTA_PENULTIMO', 'VL_CONTA']]\n",
    "\n",
    "# View the final DataFrame\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df\n",
    "#df = df_backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa816d",
   "metadata": {},
   "source": [
    "#### Transposing data from rows to columns based on CD_CONTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicating CD_CONTA column to match to VL_CONTA_PENULTIMO column\n",
    "df['CD_CONTA_PENULTIMO'] = df['CD_CONTA']\n",
    "# Reorder the columns to move 'CD_CONTA' to the 2nd position\n",
    "cols = list(df.columns)\n",
    "cols.remove('CD_CONTA_PENULTIMO')\n",
    "cols.insert(2, 'CD_CONTA_PENULTIMO')\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd586306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data\n",
    "print(\"\\n\")\n",
    "print(f'grouping rows')\n",
    "#df_pivot = df.pivot_table(index=['DT_REFER', 'CD_CVM', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC'], columns=['CD_CONTA_PENULTIMO', 'CD_CONTA'], values=['VL_CONTA_PENULTIMO', 'VL_CONTA'], dropna=True).reset_index()\n",
    "\n",
    "#df_pivot = df.groupby(['DT_REFER', 'CD_CVM', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC'])\n",
    "\n",
    "#df_pivot = df.pivot_table(index=['DT_REFER', 'CD_CVM', 'CD_CONTA', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC']).reset_index()\n",
    "\n",
    "\n",
    "#------------------------\n",
    "\n",
    "# Combine 'CD_CONTA' and 'VL_CONTA' to create new column names\n",
    "# df['CD_CONTA'] = df['CD_CONTA'].astype(str)\n",
    "# df['CD_CONTA'] = df['CD_CONTA'] + '_' + df['VL_CONTA'].astype(str)\n",
    "\n",
    "# # Pivot the DataFrame\n",
    "# pivot_df = df.pivot(index=['DT_REFER', 'CD_CVM', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC'],\n",
    "#                     columns='CD_CONTA',\n",
    "#                     values=['VL_CONTA_PENULTIMO', 'VL_CONTA']).reset_index()\n",
    "\n",
    "# # Flatten the multi-level columns\n",
    "# pivot_df.columns = [' '.join(col).strip() for col in pivot_df.columns.values]\n",
    "\n",
    "# # Drop the index name\n",
    "# pivot_df.index.name = None\n",
    "\n",
    "# # Fill NaN values with empty strings\n",
    "# pivot_df = pivot_df.fillna('')\n",
    "\n",
    "#------------------------\n",
    "\n",
    "\n",
    "# DT_REFER\tCD_CVM\tCD_CONTA\tDT_INI_EXERC_PENULTIMO\tDT_INI_EXERC\tDT_FIM_EXERC_PENULTIMO\tDT_FIM_EXERC\tVL_CONTA_PENULTIMO\tVL_CONTA\n",
    "# 0\t2012-03-31\t94\t1\t2011-10-01\t2012-01-01\t2011-12-31\t2012-03-31\t294757000.0\t314589000.0\n",
    "# 1\t2012-03-31\t94\t1.01\t2011-10-01\t2012-01-01\t2011-12-31\t2012-03-31\t225588000.0\t241973000.0\n",
    "# 2\t2012-03-31\t94\t1.01.01\t2011-10-01\t2012-01-01\t2011-12-31\t2012-03-31\t2649000.0\t1825000.0\n",
    "# 3\t2012-03-31\t94\t1.01.03\t2011-10-01\t2012-01-01\t2011-12-31\t2012-03-31\t57240000.0\t68195000.0\n",
    "# 4\t2012-03-31\t94\t1.01.04\t2011-10-01\t2012-01-01\t2011-12-31\t2012-03-31\t57123000.0\t58077000.0\n",
    "\n",
    "df['CD_CONTA'] = df['CD_CONTA'].astype(str)\n",
    "# Combine 'CD_CONTA' and 'VL_CONTA_PENULTIMO' to create new column name\n",
    "df['CD_CONTA__VL_CONTA_PENULTIMO'] = df['CD_CONTA'] + '__' + df['VL_CONTA_PENULTIMO'].astype(str)\n",
    "# Combine 'CD_CONTA' and 'VL_CONTA' to create new column name\n",
    "df['CD_CONTA__VL_CONTA'] = df['CD_CONTA'] + '__' + df['VL_CONTA'].astype(str)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df.pivot_table(index=['DT_REFER', 'CD_CVM', 'DT_INI_EXERC_PENULTIMO', 'DT_INI_EXERC', 'DT_FIM_EXERC_PENULTIMO', 'DT_FIM_EXERC'], \n",
    "                          columns=['CD_CONTA__VL_CONTA_PENULTIMO', 'CD_CONTA__VL_CONTA'], \n",
    "                          values=['VL_CONTA_PENULTIMO', 'VL_CONTA'])\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "pivot_df.columns = [' '.join(col).strip() for col in pivot_df.columns.values]\n",
    "\n",
    "# Reset the index\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "#------------------------\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('\\ndtypes:')\n",
    "print(pivot_df.dtypes)\n",
    "print('\\nshape:')\n",
    "print(pivot_df.shape)\n",
    "print('\\ncolumns:')\n",
    "print(pivot_df.columns)\n",
    "\n",
    "print('\\n')\n",
    "pivot_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21125d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3a0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
